---
title: "EDUC 152. Intro to quantitative research in education: Regression analysis"
subtitle: "Statistical inference"
author: 
date: 
urlcolor: blue
output: 
  html_document:
    toc: true
    toc_depth: 2
    toc_float: true # toc_float option to float the table of contents to the left of the main document content. floating table of contents will always be visible even when the document is scrolled
      #collapsed: false # collapsed (defaults to TRUE) controls whether the TOC appears with only the top-level (e.g., H2) headers. If collapsed initially, the TOC is automatically expanded inline when necessary
      #smooth_scroll: true # smooth_scroll (defaults to TRUE) controls whether page scrolls are animated when TOC items are navigated to via mouse clicks
    number_sections: true
    fig_caption: true # ? this option doesn't seem to be working for figure inserted below outside of r code chunk    
    highlight: tango # Supported styles include "default", "tango", "pygments", "kate", "monochrome", "espresso", "zenburn", and "haddock" (specify null to prevent syntax    
    theme: default # theme specifies the Bootstrap theme to use for the page. Valid themes include default, cerulean, journal, flatly, readable, spacelab, united, cosmo, lumen, paper, sandstone, simplex, and yeti.
    df_print: tibble #options: default, tibble, paged
bibliography: ../../assets/bib/educ152_bib.bib
csl: ../../assets/bib/apa.csl
---


<!-- Code to enable scroll right for printing of data frames -->
<style>
pre code, pre, code {
  white-space: pre !important;
  overflow-x: auto !important;
  word-break: keep-all !important;
  word-wrap: initial !important;
}
</style>


```{r, echo=FALSE, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE, comment = "#>", highlight = TRUE, warning = FALSE, message = FALSE)
  #comment = "#>" makes it so results from a code chunk start with "#>"; default is "##"
options(scipen=999)
options(tibble.width = Inf, width = 10000) # Code necessary to enable scroll right for printing of data frames
```

# Introduction

[Statistical inference](https://www.google.com/search?q=define+%22statistical+inference%22&sxsrf=ALeKk00lHj1hQ5jc8o_Xjsc7vOF6XFMPUg%3A1617292004292&ei=5OplYNCzEdOU-gTl2p_ACQ&oq=define+%22statistical+inference%22&gs_lcp=Cgdnd3Mtd2l6EAMyBwgAEEcQsAMyBwgAEEcQsAMyBwgAEEcQsAMyBwgAEEcQsAMyBwgAEEcQsAMyBwgAEEcQsAMyBwgAEEcQsAMyBwgAEEcQsANQAFgAYPbvD2gBcAJ4AIABvgGIAb4BkgEDMC4xmAEAqgEHZ3dzLXdpesgBCMABAQ&sclient=gws-wiz&ved=0ahUKEwjQtaebst3vAhVTip4KHWXtB5gQ4dUDCA0&uact=5)

> The theory, methods, and practice of forming judgments about the parameters of a population and the reliability of statistical relationships, typically on the basis of random sampling 


[Causal inference](https://en.wikipedia.org/wiki/Causal_inference)

> Causal inference is the process of determining the independent, actual effect of a particular phenomenon that is a component of a larger system

- said differently, the process of identifying the effect of an independent variable on an outcome of interest


<br>

## Example research questions

We will use two different example research questions to explain causal inference concepts:

1. **What is the effect of participating in the Mexican American Studies (MAS) program ($T_i=1$) vs. not participating in MAS ($T_i=0$) on statewide standardized high school test score ($Y$) for students in the Tucson Unified School District [@RN3292]?**
    - Cabrera, N. L., Milem, J. F., Jaquette, O., & Marx, R. (2014). Missing the (student achievement) forest for all the (political) trees: Empiricism and the Mexican American Studies controversy in Tucson. *American Educational Research Journal*, 51(6), 1084-1118.
    - This study was an observational research design, rather than an experiment. Cannot use the data because I am not allowed to share, but good example for introducing causal effects
    - *Note*. in @RN3292, we modeled the effect of MAS participation on probability of high school graduation and on statewide standardized test scores (in writing, reading, and math)
      - in this lecture, we use $Y=$ statewide standardized test score because easier to explain Rubin's causal model using a continuous outcome variable

<br>

2. **What is the effect of having a "small" class size ($T_i=1$) vs. "large" class size ($T_i=0$) on reading test score ($Y$) for elementary school students?**
    - This research question is from the Tennessee Student Teacher Achievement Ratio (STAR) experiment
    - We have data from this experiment
    - [LINK](https://dataverse.harvard.edu/dataset.xhtml?persistentId=hdl:1902.1/10766) to information and data on the Tennessee STAR project

Note: I got the data from the `AER` package (code chunk not run)
```{r, eval = FALSE}
#install.packages('AER')
library(AER)

data(STAR) # load data frame
```

LINK of script to process STAR data

## Libraries, data, functions


```{r}
# uncomment below line to remove all objects
  #rm(list = ls())

# Libraries
  #install.packages('tidyverse') # if you haven't installed already
  #install.packages('labelled') # if you haven't installed already
  #install.packages('patchwork') # if you haven't installed already

library(tidyverse) # load tidyverse package
library(labelled) # load labelled package package
library(patchwork)

##########
########## RUN SCRIPT THAT CREATES USER DEFINED FUNCTIONS
##########

source(file = url('https://github.com/anyone-can-cook/educ152/raw/main/scripts/user_defined_functions/create_inference_functions.R'))

##########
########## IPEDS
##########

# Load ipeds dataset from course website url
load(file = url('https://github.com/anyone-can-cook/educ152/raw/main/data/ipeds/output_data/panel_data.RData'))

# Create ipeds data frame with fewer variables/observations
df_ipeds_pop <- panel_data %>%
  # keep data from fall 2019
  filter(year == 2019) %>%
  # which universities to keep:
    # 2015 carnegie classification: keep research universities (15,16,17) and master's universities (18,19,20)
  filter(c15basic %in% c(15,16,17,18,19,20)) %>%
  # which variables to keep
  select(instnm,unitid,opeid6,opeid,control,c15basic,stabbr,city,zip,locale,obereg, # basic institutional characteristics
         tuition6,fee6,tuition7,fee7, # avg tuition and fees for full-time grad, in-state and out-of-state
         isprof3,ispfee3,osprof3,ospfee3, # avg tuition and fees for MD, in-state and out-of-state
         isprof9,ispfee9,osprof9,ospfee9, # avg tuition and fees for Law, in-state and out-of-state
         chg4ay3,chg7ay3,chg8ay3) %>% # [undergraduate] books+supplies; off-campus (not with family) room and board; off-campus (not with family) other expenses
  # rename variables; syntax <new_name> = <old_name>
  rename(region = obereg, # revion
         tuit_grad_res = tuition6, fee_grad_res = fee6, tuit_grad_nres = tuition7, fee_grad_nres = fee7, # grad
         tuit_md_res = isprof3, fee_md_res = ispfee3, tuit_md_nres = osprof3, fee_md_nres = ospfee3, # md
         tuit_law_res = isprof9, fee_law_res = ispfee9, tuit_law_nres = osprof9, fee_law_nres = ospfee9, # law
         books_supplies = chg4ay3, roomboard_off = chg7ay3, oth_expense_off = chg8ay3) %>% # [undergraduate] expenses
  # create measures of tuition+fees
  mutate(
    tuitfee_grad_res = tuit_grad_res + fee_grad_res, # graduate, state resident
    tuitfee_grad_nres = tuit_grad_nres + fee_grad_nres, # graduate, non-resident
    tuitfee_md_res = tuit_md_res + fee_md_res, # MD, state resident
    tuitfee_md_nres = tuit_md_nres + fee_md_nres, # MD, non-resident
    tuitfee_law_res = tuit_law_res + fee_law_res, # Law, state resident
    tuitfee_law_nres = tuit_law_nres + fee_law_nres) %>% # Law, non-resident  
  # create measures of cost-of-attendance (COA) as the sum of tuition, fees, book, living expenses
  mutate(
    coa_grad_res = tuit_grad_res + fee_grad_res + books_supplies + roomboard_off + oth_expense_off, # graduate, state resident
    coa_grad_nres = tuit_grad_nres + fee_grad_nres + books_supplies + roomboard_off + oth_expense_off, # graduate, non-resident
    coa_md_res = tuit_md_res + fee_md_res + books_supplies + roomboard_off + oth_expense_off, # MD, state resident
    coa_md_nres = tuit_md_nres + fee_md_nres + books_supplies + roomboard_off + oth_expense_off, # MD, non-resident
    coa_law_res = tuit_law_res + fee_law_res + books_supplies + roomboard_off + oth_expense_off, # Law, state resident
    coa_law_nres = tuit_law_nres + fee_law_nres + books_supplies + roomboard_off + oth_expense_off) %>% # Law, non-resident    
  # keep only observations that have non-missing values for the variable coa_grad_res
    # this does cause us to lose some interesting universities, but doing this will eliminate some needless complications with respect to learning core concepts about statistical inference
  filter(!is.na(coa_grad_res))

# Add variable labels to the tuit+fees variables and coa variables
  # tuition + fees variables
    var_label(df_ipeds_pop[['tuitfee_grad_res']]) <- 'graduate, full-time, resident; avg tuition + required fees'
    var_label(df_ipeds_pop[['tuitfee_grad_nres']]) <- 'graduate, full-time, non-resident; avg tuition + required fees'
    var_label(df_ipeds_pop[['tuitfee_md_res']]) <- 'MD, full-time, state resident; avg tuition + required fees'
    var_label(df_ipeds_pop[['tuitfee_md_nres']]) <- 'MD, full-time, non-resident; avg tuition + required fees'
    var_label(df_ipeds_pop[['tuitfee_law_res']]) <- 'Law, full-time, state resident; avg tuition + required fees'
    var_label(df_ipeds_pop[['tuitfee_law_nres']]) <- 'Law, full-time, non-resident; avg tuition + required fees'
    
  # COA variables
    var_label(df_ipeds_pop[['coa_grad_res']]) <- 'graduate, full-time, state resident COA; == tuition + fees + (ug) books/supplies + (ug) off-campus room and board + (ug) off-campus other expenses'
    var_label(df_ipeds_pop[['coa_grad_nres']]) <- 'graduate, full-time, non-resident COA; == tuition + fees + (ug) books/supplies + (ug) off-campus room and board + (ug) off-campus other expenses'
    var_label(df_ipeds_pop[['coa_md_res']]) <- 'MD, full-time, state resident COA; == tuition + fees + (ug) books/supplies + (ug) off-campus room and board + (ug) off-campus other expenses'
    var_label(df_ipeds_pop[['coa_md_nres']]) <- 'MD, full-time, non-resident COA; == tuition + fees + (ug) books/supplies + (ug) off-campus room and board + (ug) off-campus other expenses'
    var_label(df_ipeds_pop[['coa_law_res']]) <- 'Law, full-time, state resident COA; == tuition + fees + (ug) books/supplies + (ug) off-campus room and board + (ug) off-campus other expenses'
    var_label(df_ipeds_pop[['coa_law_nres']]) <- 'Law, full-time, non-resident COA; == tuition + fees + (ug) books/supplies + (ug) off-campus room and board + (ug) off-campus other expenses'

df_ipeds_pop %>% glimpse()


##########
########## Create data frame of generated variables, with each variable meant to represent the entire population
##########


num_obs <- 10000

# Generate normal distribution w/ custom mean and sd
set.seed(124)
norm_dist <- rnorm(n = num_obs, mean = 50, sd = 5)

# Generate right-skewed distribution
set.seed(124)
rskew_dist <- rbeta(n = num_obs, shape1 = 2, shape2 = 5)

# Generate left-skewed distribution
set.seed(124)
lskew_dist <- rbeta(n = num_obs, shape1 = 5, shape2 = 2)

# Generate standard normal distribution (default is mean = 0 and sd = 1)
set.seed(124)
stdnorm_dist <- rnorm(n = num_obs, mean = 0, sd = 1)  # equivalent to rnorm(10)

# Create dataframe
df_generated_pop <- data.frame(norm_dist, rskew_dist, lskew_dist, stdnorm_dist)

# drop individual objects associated with each variable
rm(norm_dist,rskew_dist,lskew_dist,stdnorm_dist)
rm(num_obs)


##########
########## Create sample versions of generated population data frame and IPEDS population data frame
##########

# create sample version of our generated data
  set.seed(124) # set seed so that everyone ends up with the same random sample
  
  df_generated_sample <- df_generated_pop %>% sample_n(size = 200)
  df_generated_sample %>% glimpse()


# create sample version of our ipeds data

  set.seed(124) # set seed so that everyone ends up with the same random sample
  
  df_ipeds_sample <- df_ipeds_pop %>% sample_n(size = 200) 

##########
########## STAR DATA
##########

# load star data
load(file = url('https://github.com/anyone-can-cook/educ152/raw/main/data/star/star_panel_data.RData'))

#df_star_panel %>% glimpse()

# create data frame for STAR experiment, keeping only kindergarten
df_stark <- df_star_panel %>% 
  # keep only kindergarten year
  filter(grade ==1) %>% 
  # keep only observations with non-missing value for reading score
  filter(!is.na(read)) %>%
  # keep only observations with non-missing values for treatment assignment
  filter(!is.na(star)) %>%
  # drop observations where treatment status is regular+aide
  filter(star !=3) %>%
  # keep selected variables
  select(id,grade,star,read,gender,ethnicity,lunch,school,degree,experience) %>%
  # create a variable "treatment" that equals 1 if student receives treatment (small class) and equals 0 otherwise
  mutate(
    treatment = if_else(star==2,1,0)
  )


df_stark %>% glimpse()
```

Investigate STAR data

- basically, we want to know if Kindergarten students randomly assigned to "small" class size (variable `treatment` equals `1`) have higher values of reading test score than students randomly assigned to "large" class size (variable `treatment` equals `0`)
```{r}
# frequency count of treatment variable
  #df_stark %>% count(star)
  #df_stark %>% count(star) %>% as_factor()
df_stark %>% count(treatment)

# calculate mean value of reading score separately for treated and nontreated
df_stark %>% group_by(treatment) %>% summarize(
  mean_read = mean(read, na.rm = TRUE),
  sd_read = sd(read, na.rm = TRUE)
)

# t.test
#t.test(formula = read ~ treatment, mu = 0, data = df_stark)
```




# Fundamentals of causal inference

## Overview of causal inference

Descriptive research questions

- Can investigate the magnitude of a problem (univariate):
	- What percentage of high school graduates attend college?
- Investigate correlational relationship between variables (sometimes called "associational" relationships):
	- Relationship between buying felt furniture pads and credit score?
	- Relationship between avg. income at a high school and the number of off-campus recruiting visits by universities?

Causal research questions

- Want to know the "causal effect" of independent variable (X) on outcome (Y); If you change value of X, causal effect is the change in Y due to the change in X
- Have the form "what is effect of X on Y?" Examples: 
  - What is the effect of class size on math scores? 
  - What is effect of grant aid on graduation?

<br>

**Example research question **

What is the effect of participating in the Mexican American Studies (MAS) program ($T_i=1$) vs. not participating in MAS ($T_i=0$) on statewide standardized high school test score ($Y$) for students in the Tucson Unified School District [@RN3292]?


**Counterfactuals**

Actual and counterfactual (using the Mexican American Studies (MAS) example)

- Actual event
  - actual treatment/control assignment and observed outcome
  - e.g., person $i$ participated in MAS ($T_i =1$) and graduated from high school ($Y_i=1$)
- counterfactual
  - for a person that received treatment, counterfactual is what outcome would have been if person had not received treatment
  - e.g., if person $i$ (who we know participated in MAS) had instead not participated in MAS ($T_i =0$), what would their value of high school graduation ($Y$) have been?


True causal effect of an intervention:
	
- Causal effect for person $i$ who actually participated in the treatment
  - The causal effect for person $i$ is the observed "treated" outcome minus the counterfactual outcome had they not been treated
- Note: causal effect could be different for each person
- What is the problem with this approach to calculating causal effects?
  - we only observe the **actual** treatment assignment and outcome
  - we do not observe the counterfactual; it is counter to fact!


**The primary challenge in program evaluation/causal inference research**

Given that the true causal effect is observed outcome minus the counterfactual outcome, the primary challenge in program evaluation methods is finding a substitute for the counterfactual

- This substitute is called the "comparison group"

 Creating comparison groups for the counterfactual
 
 1. treated vs. untreated research designs (cross-sectional)
     - use "untreated" groups as "comparison group" for treated
 2. before vs. after research designs (longitudinal)
     - use "outcome before treatment" groups as comparison group for "outcome after treatment"
 3. Some research designs use both cross-sectional and longitudinal variation (e.g., "difference-in-difference")
		

**Treated vs. untreated research designs**
	
- Use "untreated" people as "comparison group" for treated
	- We use non-participants to represent the counterfactual for participants (i.e., what would have happened to participants if they hadn't participated)
- Example:
	- What is effect of participation in MAS on HS graduation?
- Estimate of causal effect based on "cross-sectional" variation (also called "between" variation)
	- Outcome measured at one point in time
	- Uses "between" variation: variation in Y between treated and untreated at time outcome variable is measured
- Sample:
	- People who participate in MAS \textbf{and} people who do not participate in MAS
- This course will focus on treated vs. untreated designs


**Before vs. after research designs**

- Use "outcome before treatment" as comparison group for "outcome after treatment"
  - Assumes outcome prior to treatment is counterfactual for outcome after treatment (i.e., what would have happened to participants if they hadn't participated)
- Example
	- What is the effect of participating in MAS (X) on days absent (Y)?
Can answer this RQ using "treated vs. untreated" or "before vs. after" methods. Let's focus on before vs. after
- Sample:
	- Only students who participate in MAS
- Calculate causal effect from longitudinal ("within" )rather than cross-sectional ("between") variation:
		- "within" variation: change over time in Y within each person
		- Must observe outcome before treatment \textbf{and} after treatment
- Most of my research uses before vs. after designs because I study change in organizational behavior over time

<!--
Major assumption: After including [time-varying] covariates, there are no omitted variables that affect outcome (graduation) and are correlated with change in X for participants
-->


**Types of treated vs. untreated designs**

1. Random assignment experiment designs
  - randomly assign each TUSD high school student to participate in MAS or not; and then observe their outcome (e.g., graduation, high school exit exam score)
2. Observational (i.e., non-experimental) "selection on observables" designs
	- These designs control for variables that affect outcome and treatment. 
	- Multivariate regression
	- Matching estimatros (e.g., propensity score matching)
3. Observational "natural experiments" designs
	- These designs utilize experimental variation in X in real world settings (e.g., access to school determined by lottery)
	- Regression discontinuity
	- Instrumental variables


**Random assignment experiments: The "gold standard" treated vs. untreated designs**

How experiments work:

- Randomly assign people to values of X (MAS or no MAS)
	- group randomly assigned to "no MAS" serves as counterfactual to group assigned to MAS
- On average, "treated" group is identical to control group on variables (e.g., parental education, math achievement) that affect outcome (e.g., graduation)
- Only difference between "treated" and "control" group is participation in treatment
- Therefore, can say that difference in outcome between treatment and control is due to treatment

Experiments can only identify **average** causal effect	

- If we knew the true counterfactual for each person, we could identify causal effect for each person


**Observational treated vs. untreated designs**
	
Observational (i.e., non-experimental) design

- People not randomly assigned to values of treatment (X)
- Rather, people self-select into treatment, or some other assignment mechanism


The problem with observational designs

- students with other characteristics (e.g., "motivation") that affect the outcome of interest may be more/less likely to participate in the treatment (e.g., MAS)
- If students in the treatment tend to have higher values of outcome variable, hard to know whether this is because of participation in the treatment (i.e., causal) or because students who participated in MAS tended to be those who were more motivated about school (correlational)

Methods for observational data (e.g., multivariate regression) attempt to recreate experimental conditions

- Important to understand why experiments work so you can assess whether the observational method is recreating experimental conditions

## Rubin's causal model

Rubin's causal model: The potential outcomes framework

- Rubin's causal model (also called "the potential outcomes framework") is the most important conceptual approach to understanding causal effects
- it lays out the logic of "true causal effect equals actual minus counterfactual" in a more rigorous way

<br>

**Notation**

- $i=1,\ldots,n$ refers to "units" or "subjects" (e.g., students)
- $Y_i$: actual observed outcome $Y$ for unit $i$
- $T_i$: actual observed treatment condition for unit $i$. $T_i=1$ is "treated"; $T_i=0$ is "untreated" or "control"


**Potential outcomes**

A **potential outcome** is what the outcome would be for a unit if it received a given treatment condition

Each person $i$ has two **potential outcomes** (using the Mexican American Studies (MAS) example)
	
1. $Y_i(1)$, the "treated potential outcome," equals the outcome for unit $i$ if it had received the treatment
1. $Y_i(0)$, the "untreated potential outcome," equals the outcome for unit $i$ if it had not received the treatment


The two **potential outcomes**, using the Mexican American Studies (MAS) example

1. $Y_i(1)$, the "treated potential outcome," equals the outcome -- statewide high school test score -- for unit $i$ if it had participated in MAS program
1. $Y_i(0)$, the "untreated potential outcome," equals the outcome -- statewide high school test score -- for unit $i$ if it had not participated in MAS program


**How to think about potential outcomes**
	
- for each person $i$, imagine that the both the treated potential outcome $Y_i(1)$ and the untreated potential outcome $Y_i(0)$ already exist
- The observed value of the treatment variable $T_i$ just determines which of the two potential outcomes we actually get to observe

<br>

Relationship between potential and observed outcomes, $Y_i$

- $Y_i=T_i*Y_i(1)+(1-T_i)*Y_i(0)$
- if subject is assigned to the treatment group ($T_i=1$) then the above equation simplifies to $Y_i=Y_i(1)$ meaning that the outcome we actually observe is the treated potential outcome, $Y_i(1)$
- if subject is assigned to the control group ($T_i=0$) then the above equation simplifies to $Y_i=Y_i(0)$ meaning that the outcome we actually observe is the untreated potential outcome, $Y_i(0)$

<br>

There are four combinations of potential outcome and treated assignment, two of which we actually observe and two of which we do not observe because they are counterfactuals

- Below, we will use this sort of notation: $Y_i(1) \mid T_i=1$ 
  - means "the treated potential outcome for unit $i$ **given** that unit $i$ actually received the treatment (i.e., $T_i=1$)


Four combinations of potential outcome and treated assignment

- $Y_i(1) \mid T_i=1$ => treated potential outcome for those actually assigned to treatment (**observed**)
  - For people actually assigned to the treatment, we get to observe their treated potential outcome
- $Y_i(0) \mid T_i=1$ => untreated potential outcome for those actually assigned to treatment (**not observed**)
  - For people actually assigned to the treatment, we do not get to observe their untreated potential outcome
- $Y_i(1) \mid T_i=0$ => treated potential outcome for those actually assigned to control (**not observed**)			
  - For people actually assigned to the control, we do not get to observe their treated potential outcome
- $Y_i(0) \mid T_i=0$ => untreated potential outcome for those actually assigned to control (**observed**)
  - For people actually assigned to the control, we get to observe their untreated potential outcome

<br>

Below, we present these four combinations of potential outcome and treatment assignment in tabular form. 

|   | **Actually treated (T=1)**  | **Actually not treated (T=0)**  |
|---|:-:|:-:|
| <b>$Y_i(1)$</b>  | <span style="color:blue;">$Y_i(1) \mid T_i=1$</span>  | <span style="color:red;">$Y_i(1) \mid T_i=0$</span>  |
| <b>$Y_i(0)$</b>  | <span style="color:red;">$Y_i(0) \mid T_i=1$  | <span style="color:blue;">$Y_i(0) \mid T_i=0$</span>  |


The <span style="color:blue;">Blue</span> cells show notation for _actual_ outcomes we get to observe (i.e., the observed outcome $Y$ is the same as the potential outcome) 

- e.g., "The treated potential outcome, for those who underwent treatment"

The <span style="color:red;">Red</span> cells are _counterfactual_ outcomes, which we never get to see (i.e., the observed outcome $Y$ is not the same as the potential outcome) 

- We need counterfactual to calculate the "true" causal effect
- Need some substitute for the counterfactual to estimate causal effect
	
**unit-level causal effect** ("true" causal effect)

Unit causal effect: $\tau_i = Y_i(1) - (Y_0)$

- in words: the causal effect of the treatment for unit $i$ is the treated potential outcome ($Y_i(1)$) -- outcome had they received the treatment -- minus the untreated potential outcome ($Y_i(0)$) -- outcome had they not received the treatment
- note that the unit causal effect differs for different subject
- in reality, we can never calculate the true unit causal effect because we can never observe both the treated potential outcome and the untreated potential outcome for a unit, $i$

**Table of potential outcomes**


But imagine we know treated $Y_i(1)$ and untreated $Y_i(0)$ potential outcomes for all $i$

| $i$ | $Y_i(1)$ <br> Treated  | $Y_i(0)$ <br> Untreated | $\tau_i$ <br> Unit effect |
|:---|--:|--:|--:|
| 1  | 65  | 60  | 5  |
| 2  | 30  | 35  | -5  |
| 3  | 55  | 60  | -5  |
| 4  | 25  | 30  | -5  |
| 5  | 50  | 50  | 0  |
| 6  | 80  | 70  | 10  |
| 7  | 45  | 45  | 0  |
| **Average**  | **50**  | **50**  | **0** |
	
True causal effect for each $i$
	
- Unit treatment effect: for each person, compare their treated potential outcome to their untreated potential outcome
- ${UTE}_i=\tau_i=Y_i(1)-Y_i(0)$


# Experiments

Calculating the true (unit) causal effect of a treatment requires knowing the actual outcome and the counterfactual outcome (the potential outcome had the unit been assigned to a different treatment/control condition than what they actually received), for each unit $i$

- we can never do this

<br>

The most important/difficult part of causal inference research is creating a "comparison group" that is a good substitute for the counterfactual

An experiment (subjects randomly assigned to treatment vs. control) is the "gold standard" approach for creating a comparison group

- when we conduct an experiment, we cannot calculate the unit treatment effect (causal effect of the treatment that is different for each unit $i$), but we can calculate an "average treatment effect"


## Expected values

Repeated random sampling
	
- Imagine we take an infinite number of samples of size N from the population

Expected value

- Expected value of a variable is the average value of a random variable based on an infinite number of samples
- expected value of discrete random variable X: $E[X]=\sum xPr[X=x]$
  - $Pr[X=x]$ is probability that $X$ takes on the value $x$, where summation is taken over all possible values of X
- Example of expected value of dice role, $X$:
	- $E[X]=(1)(\frac{1}{6}) +(2)(\frac{1}{6})+(3)(\frac{1}{6})+(4)(\frac{1}{6})+(5)(\frac{1}{6})+(6)(\frac{1}{6})=3.5$

### Conditional expectations

Conditional expectations refer to subgroup averages 

Using Tennesee STAR example: $Y_i$=achievement test score; $T_i$=treatment assignment (1="small" class, treated; 0="big" class, untreated); $Z_i$=parental education
	
- $E[Y_i|T_i=1]$
	- Expected value of observed test score, given that student got internship
- $E[Y_i|Z_i >= baccalaureate\_degree"]$
	- Expected value of observed test score, given that parents level of education is baccalaureate degree or higher
- $E[Y_i(1)|T_i=1]$
	- Expected value of treated potential outcome test score, given that student received the treatment (assigned to small class) [we get to observe this]
- $E[Y_i(0)|T_i=1]$
	- Expected value of untreated potential outcome test score, given that student received the treatment  [we do not get to observe this]

## Random assignment

In an experiment, we randomly assign subjects to receive treatment or not (i.e., control)

Random assignment variable, $T_i$

- $T_i$ is a variable whose value is randomly assigned (e.g., coin flip, or some random number generator)
- Value of $T_i$ determines whether person $i$ receives treatment
  - e.g., student with $T_i=1$ enroll in "small class" (treatment); units with $T_i=0$ enroll in "big class" (control)

Potential outcomes and random assignment

- $E[Y_i(1)|T_i=1]$
	- Treated potential outcome, given $i$ assigned to treatment
	- Observed?: Yes 
- $E[Y_i(1)|T_i=0]$
	- Treated potential outcome, given $i$ not assigned to treatment
	- Observed?: No 			
- $E[Y_i(0)|T_i=1]$
	- Untreated potential outcome, given $i$ assigned to treatment
	- Observed?: No		
- $E[Y_i(0)|T_i=0]$
	- Untreated potential outcome, given $i$ not assigned to treatment
	- Observed?: Yes
	
### Random assignment and repeated random sampling

Below table shows table of treated and untreated potential outcomes for 7 people, in the hypothetical case where we know both the treated and untreated potential outcome for each person

- Imagine that we take a random sample of 7 people from the population


| $i$ | $Y_i(1)$ <br> Treated  | $Y_i(0)$ <br> Untreated | $\tau_i$ <br> Treatment effect |
|:---|--:|--:|--:|
| 1  | 65  | 60  | 5  |
| 2  | 30  | 35  | -5  |
| 3  | 55  | 60  | -5  |
| 4  | 25  | 30  | -5  |
| 5  | 50  | 50  | 0  |
| 6  | 80  | 70  | 10  |
| 7  | 45  | 45  | 0  |
| **Average**  | **50**  | **50**  | **0** |

Below equations show the the calculation of average treatment effect (ATE)

$ATE \equiv \frac{1}{N} \sum_{i=1}^{N} \tau_i$

$ATE \equiv \frac{1}{N} \sum_{i=1}^{N} Y_i(1) - \frac{1}{N} \sum_{i=1}^{N} Y_i(0) = \frac{1}{N} \sum_{i=1}^{N} (Y_i(1)-Y_i(0)) = \frac{1}{N} \sum_{i=1}^{N} \tau_i$

<br>

Now imagine that 3 of the 7 people are randomly assigned to receive the treatment (small class size)

- we randomly sample 7 people from the population; of those 7 people we randomly assign 3 people to receive the treatment


in the below table, **bolded** cells indicate cells we actually observe

- e.g., in the first row for unit $i=1$ we observe the untreated outcome $Y_i(0)=60$ (indicating that $T_i=0$ for unit $i=1$), but we would not observe the treated outcome $Y_i(1)=65$ because unit $i=1$ was not assigned to the treatment

| $i$ | $Y_i(1)$ <br> Treated  | $Y_i(0)$ <br> Untreated | $\tau_i$ <br> Treatment effect |
|:---|--:|--:|--:|
| 1  | 65  | **60**  | ?  |
| 2  | 30  | **35**  | ?  |
| 3  | **55**  | 60  | ?  |
| 4  | **25**  | 30  | ?  |
| 5  | 50  | **50**  | ?  |
| 6  | 80  | **70**  | ?  |
| 7  | **45**  | 45  | ?  |
| **Avg. observed**  | **45**  | **53.75**  | **-8.75** |
| Avg. potential (unobserved)  | 50  | 50  | 0 |


<br>

Now imagine that start over (re-sample) and randomly assign 3 of the 7 people people to receive the treatment

- we randomly sample 7 people from the population; of those 7 people we randomly assign 3 people to receive the treatment
- *Note*
  - compared to previous table, what has changed is which 3 people (of the 7) receives the treatment; but we sample the same 7 people as before
  - If we re-sampled in real life, we our random sample of 7 people would be a different set of people than the first time we randomly sampled; however, we keep it as the same 7 people because this meakes it easier to explain the concepts



| $i$ | $Y_i(1)$ <br> Treated  | $Y_i(0)$ <br> Untreated | $\tau_i$ <br> Treatment effect |
|:---|--:|--:|--:|
| 1  | **65**  | 60  | 5  |
| 2  | 30  | **35**  | -5  |
| 3  | 55  | **60**  | -5  |
| 4  | **25**  | 30  | -5  |
| 5  | 50  | **50**  | 0  |
| 6  | **80**  | 70  | 10  |
| 7  | 45  | **45**  | 0  |
| **Avg. observed**  | **56.67**  | **47.5**  | **9.17** |
| Avg. potential (unobserved)  | 50  | 50  | 0 |
	
	
**If we re-sampled an infinite number of times, and calculated the average of the "average observed treatment effect" it would equal the "average potential treatment effect"**

- this is the exaxt same idea as: if we take an infinite number of random samples and calculate the sample mean $\bar{Y}$ for each sample, the mean of all sample means would equal the population mean, $\mu_Y$

## Why experiments work

Why are experiments viewed as the "gold standard" approach for estimating causal effects?

<br>

Recall from Rubin's causal model:

- for each person $i$, both the value of the treated potential outcome $Y_i(1)$ and the value of the untreated potential outcome $Y_i(0)$ already exist
- The observed value of the treatment variable $T_i$ just determines which of the two potential outcomes we actually get to observe, $Y_i$
  - If $T_i=1$ then the observed outcome, $Y_i$, is the treated potential outcome, $Y_i(1)$
  - If $T_i=0$ then the observed outcome, $Y_i$, is the untreated potential outcome, $Y_i(0)$

<br>

In experiments, treatment status is randomly assigned (if $T_i=1$ then treated; $T_i=0$ then untreated)

- treatment assignment $T_i$ does not affect the value of the either the treated potential outcome ($Y_i(1)$) or the untreated potential outcome ($Y_i(0)$)
- rather, treatment assignment $T_i$ just affects which treated potential outcome we observe
  - If $T_i=1$ then the observed outcome, $Y_i$, is the treated potential outcome, $Y_i(1)$
  - If $T_i=0$ then the observed outcome, $Y_i$, is the untreated potential outcome, $Y_i(0)$

<br>

**Random assignment and expected values**

- Every person has same probability of getting treatment ($T_i=1$); therefore, expected treated potential outcome among treated people ($E[Y_i(1)|T_i=1]$) is same as expected treated outcome for all people in sample ($E[Y_i(1)]$):
	- $E[Y_i(1)|T_i=1]=E[Y_i(1)]$
- Every person has same probability of getting control  ($T_i=0$); therefore, expected untreated potential outcome among untreated people ($E[Y_i(0)|T_i=0]$) is same as expected outcome for all people in sample ($E[Y_i(0)]$):
	- $E[Y_i(0)|T_i=0]=E[Y_i(0)]$


<br>

**Why experiments work (i.e., why they calculate unbiased estimates of causal effects**

For any outcome of interest (e.g., reading achievement scores of 3rd graders), there are many variables -- aside from the treatment (e.g., "small class size") -- that affect the value of the outcome

- e.g., parental education; household income; access to a quiet place to do homework; access to good nutrition; sleep

<br>

But because assignment to treatment is random:
 
- Assignment to treatment has no effect on value of the potential outcomes; it just affects which potential outcome is observed for each person
- **Assignment to treatment has no relationship to characteristics (e.g., parental income) that affect value of potential outcomes**

<br>

**Why observational studies (people self-select into treatment) don't calculate unbiased estimates of causal effects**

For any outcome of interest (e.g., reading achievement scores of 3rd graders), there are many variables -- aside from the treatment (e.g., "small class size") -- that affect the value of the outcome

- e.g., parental education; household income; access to a quiet place to do homework; access to good nutrition; sleep

When people self-select into the treatment (as opposed to treatment being randomly assigned), it is likely that people with certain characteristics are more likely to select into the treatment than others

- e.g., affluent parents are more likely to get their children into classes with small class size

So in observational research designs, the same characteristics (e.g., parental income) that determine the value of the dependent variable (student achievement score) also drive selection into the treatment (small class size)

- This makes it difficult to determine whether the higher outcome values for "treated" units are due to the treatment or due to other characteristics that are associated with both the treatment and the outcome

<br>

**Calculating average treatment effects (ATE) for random assingment experiments**

In a random assignment experiment, we can calculate the population average treatment effect (ATE) as follows

- $ATE=\tau=E[Y_i(1)-Y_i(0)]=  E[Y_i(1)] - E[Y_i(0)] = E[Y_i(1)|T_i=1]-E[Y_i(0)|T_i=0]= E[Y_i|T_i=1] - E[Y_i|T_i=0]$

However, knowing expected values -- e.g., $E[Y_i|T_i=1]$, the expected value of $Y_i$ amongst treated units -- requires taking an infinute number of samples

- In real research, we are only able to randomly assign a single sample
- Using data from that single sample we calculate an estimate of the average treatment effect
- Using hypothesis testing methods we learned previously, we use our estimate of the average treatment effect to test hypotheses about the population treatment effect

Formula for the "difference in means" estimator of the average treatment effect

- $\hat{ATE} = \hat{\tau} = \bar{Y}_{treat} - \bar{Y}_{control}$

<br>
Using data from Tenesse STAR experiment (data frame is `df_stark`), our estimate of ATE is the sample mean reading score for treated students (small class size) minus the sample mean reading score for untreated units (big class size)

- sample mean reading score for treated units = `r round(mean(df_stark$read[df_stark$treatment==1], na.rm = TRUE), digits=2)`
- sample mean reading score for untreated units = `r round(mean(df_stark$read[df_stark$treatment==1], na.rm = TRUE), digits=2)`
- difference between means estimate = `r round(mean(df_stark$read[df_stark$treatment==1], na.rm = TRUE) - mean(df_stark$read[df_stark$treatment==0], na.rm = TRUE), digits=2)`

```{r}
# number of observations in treatment and control
df_stark %>% count(treatment)

# sample mean reading score for treated units
mean(df_stark$read[df_stark$treatment==1], na.rm = TRUE)

# sample mean reading score for untreated unts
mean(df_stark$read[df_stark$treatment==0], na.rm = TRUE)

# difference between means estimator
mean(df_stark$read[df_stark$treatment==1], na.rm = TRUE) - mean(df_stark$read[df_stark$treatment==0], na.rm = TRUE)

# alternative approach to calculating mean value of reading score separately for treated and nontreated
df_stark %>% group_by(treatment) %>% summarize(
  mean_read = mean(read, na.rm = TRUE),
  sd_read = sd(read, na.rm = TRUE)
)
```


# Hypothesis testing about two populations

This section explains how to test hypotheses about whether the population mean for one group is different from the population mean for another group

- The approach we introduce is the approach used to estimate causal effects in experiments where there is one treatment group and one control group
  - Using data from Tennessee STAR, we will test whether kindergarten students assigned to small class size (treatment) have higher reading scores than kindergarten students assigned to big class size (control)
- The approach we introduce is also the approach used to compare population means of two groups in non experimental settings
  - using a random sample of data from IPEDS (each observation is a university), we will test the null hypothesis that $H_0$ that population mean value of a variable for one group is the same as that of another group (e.g., population mean grad-school tuition+fees at private universities is the same as population mean grad-school tuition+fees at public universities)


## Steps in hypothesis testing about two populations

The steps in testing hypotheses about whether the population mean of a variable differs between two groups are the exact same as the steps for testing hypothesis about the population mean for a single group

- so don't think of this as learning something new. think of this as applying something you already know, with a few modest variations

<br>

General steps in hypothesis testing:

1. **Hypothesis**
    - formally state your "null" and "alternative" hypothesis
    - usually, you would decide on alpha level (rejection region) here
1. **Assumptions**
    - state assumptions that are relied upon by the statistical test you are using to test your hypothesis
1. **Test statistic**
    - Using some appropriate statistical analysis, calculate the "test statistic" necessary to test your hypothesis
1. **p-value (means probability value)**
    - calculate the probability of observing a test statistic as large or larger as the one you calculated
1. **Alpha level/rejection region and conclusion**
    - compare the p-value you you observed to the alpha level and make a conclusion about your hypothesis test


## Conceptual understanding [MOST IMPORTANT!]

We will use IPEDS data to provide conceptual understanding of hypothesis tests about comparing two means. 

- Why? because for IPEDS we have data on the entire population, which is useful for explaining concepts
- Key to conceputal understanding is realizing that hypothesis tests about comparing two means is conceptually the same as hypothesis tests about the value of a single population mean

<br>

### Introduce user defined functions

We'll use our "user defined functions" (loaded above) to visually explain core concepts

- these functions have been updated/modified as of 4/15/2021


`plot_distribution()` function plots the distribution of variables

- syntax and default values: 
  - `plot_distribution(data_vec1, data_vec2 = NULL, data_df = NULL, data_var = NULL, group_var = NULL, group_cat = NULL, pop_labels = NULL, show_group_hist = F, sampling_dist = F, plot_title = '')`
- We can use this function to plot the distribution of a single variable, or to plot distribution of variable for two different groups (or two different variables)

```{r}
# PLOTTING A SINGLE DISTRIBUTION
  plot_distribution(data_df = df_ipeds_pop, data_var = 'tuitfee_grad_res')

# PLOTTING TWO DISTRIBUTIONS
  plot_distribution(data_df = df_ipeds_pop, data_var = 'tuitfee_grad_res', group_var = 'control',group_cat = c(1, 2), pop_labels = c('Public', 'Private not-for-profit'))

```

`get_sampling_distribution()` function gets the sampling distribution of a variable (defaults = 1000 samples of sample size = 200)

- syntax and default values: 
  - `get_sampling_distribution(data_vec, num_samples = 1000, sample_size = 200)`
- following revisions to the `plot_distribution()` function, we usually will not call the `get_sampling_distribution()` function directly; 
  - rather, a we can specify an optional argument within the `plot_distribution()` to call the `get_sampling_distribution()`
  - the relevant argument within `plot_distribution()` function is `sampling_dist` which has a default value of `FALSE`

```{r}
# PLOT SAMPLING DISTRIBUTION, SINGLE POPULATION, 
  #(set sampling_dist= TRUE) to plot sampling distribution
  plot_distribution(data_df = df_ipeds_pop, data_var = 'tuitfee_grad_res', sampling_dist = TRUE, plot_title = 'this is a sampling distribution')

  #(set sampling_dist= FALSE) to plot distribution of the variable (not the sampling distribution)
  plot_distribution(data_df = df_ipeds_pop, data_var = 'tuitfee_grad_res', sampling_dist = FALSE, plot_title = 'this is a variable distribution')
    
     the sampling distribution
    #plot_distribution(df_ipeds_pop$tuitfee_grad_res, sampling_dist = T) # this works too

# PLOT SAMPLING DISTRIBUTION OF TWO POPULATIONS     
    
    plot_distribution(data_df = df_ipeds_pop, data_var = 'tuitfee_grad_res', sampling_dist = F) # sampling_dist = F plots underlying variable  
```


## Null and alternative hypothesis

null hypothesis ($H_0$)

- $H_0: \mu_{Y_{{treated}}} = \mu_{Y_{{control}}}$
- (in words): $H_0:$ the population mean reading score for kindergarten students assigned to the treatment (small class size), $\mu_{Y_{{treated}}}$, is the same as the population mean reading score for kindergarten students assigned to the control (big class size) ($\mu_{Y_{{control}}}$)

Two-sided alternative hypothesis ($H_a$)

- $H_0: \mu_{Y_{{treated}}} \ne \mu_{Y_{{control}}}$
- (in words): $H_0:$ the population mean reading score for kindergarten students assigned to the treatment (small class size), $\mu_{Y_{{treated}}}$, is different than the population mean reading score for kindergarten students assigned to the control (big class size) ($\mu_{Y_{{control}}}$)


## Test statistic and p-value

## Alpha level and conclusion


# References